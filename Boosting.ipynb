{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"master_dataset/processed_data.csv\")\n",
    "#list(data.columns)\n",
    "#drop unwanted features\n",
    "data = data.drop(['title', 'text', 'subject', 'date', 'text_without_stopwords', 'title_without_stopwords','syllables', 'polarity_category', 'overall_content', 'polarity'], axis=1)\n",
    "#'Topic 1 Probability', 'Topic 2 Probability', 'Topic 3 Probbility' , 'Topic 4 Probability' ,'Topic 5 Probability',\n",
    "#'title_word_count', 'title_sentence_count', 'title_average_word_length','title_punctuation_count', 'title_stopwords_count'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    21196\n",
       "1    17462\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataset is slightly imbalanced so we will perform upsampling to balance the dataset.\n",
    "data['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['class',\n",
       " 'text_word_count',\n",
       " 'title_word_count',\n",
       " 'text_sentence_count',\n",
       " 'title_sentence_count',\n",
       " 'text_average_word_length',\n",
       " 'title_average_word_length',\n",
       " 'text_punctuation_count',\n",
       " 'title_punctuation_count',\n",
       " 'text_stopwords_count',\n",
       " 'title_stopwords_count',\n",
       " 'flesch_readability',\n",
       " 'subjectivity',\n",
       " 'Topic 1 Probability',\n",
       " 'Topic 2 Probability',\n",
       " 'Topic 3 Probbility',\n",
       " 'Topic 4 Probability',\n",
       " 'Topic 5 Probability',\n",
       " 'polarity_category_Neutral',\n",
       " 'polarity_category_Positive']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#first split the dataset into training and test sets\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "x = data.iloc[:,1:]\n",
    "y = data.iloc[:,:1]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.3,random_state = 1)\n",
    "\n",
    "#balance x_train with oversampling\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "oversample = RandomOverSampler(sampling_strategy = 1)\n",
    "x_train,y_train = oversample.fit_resample(x_train, y_train)\n",
    "data = pd.concat([x_train,y_train],axis = 1)\n",
    "\n",
    "#check that train set is oversampled\n",
    "data['class'].value_counts()\n",
    "\n",
    "#Ensemble methods such as XGBoost and AdaBoost do not require feature scaling.\n",
    "type(y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9686152784962925\n",
      "Precision: 0.9643059490084985\n",
      "Recall: 0.9668623366786594\n",
      "F1_score: 0.9655824508320726\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "#Ada Boost baseline model\n",
    "# we will use unscaled x_train and x_test sets here.\n",
    "\n",
    "ada_boost = AdaBoostClassifier( random_state = 1)\n",
    "ada_boost.fit(x_train, np.ravel(y_train))\n",
    "y_pred_ada_boost = ada_boost.predict(x_test)\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_ada_boost))\n",
    "print(\"Precision:\", metrics.precision_score(y_test, y_pred_ada_boost))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred_ada_boost))\n",
    "print(\"F1_score:\", metrics.f1_score(y_test, y_pred_ada_boost))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yj_li\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyper Parameters:  {'algorithm': 'SAMME.R', 'learning_rate': 1, 'n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "#hyperparameter tuning with gridsearch for Ada Boost\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_params = {\n",
    "    'n_estimators': [50, 100, 200,500,1000],\n",
    "    'learning_rate': [0.01, 0.1, 0.5, 1, 10],\n",
    "    'algorithm': ['SAMME', 'SAMME.R'],\n",
    "}\n",
    "scorer = metrics.make_scorer(metrics.f1_score)\n",
    "\n",
    "gridCV = GridSearchCV(AdaBoostClassifier(random_state = 1), param_grid = grid_params, cv = 5, scoring = scorer, n_jobs=-1)\n",
    "gridCV.fit(x_train,np.ravel(y_train))\n",
    "print(\"Best Hyper Parameters: \", gridCV.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9745645801000172\n",
      "Precision: 0.9752192146397255\n",
      "Recall: 0.9687559174398788\n",
      "F1_score: 0.971976821506602\n"
     ]
    }
   ],
   "source": [
    "ada_boost = AdaBoostClassifier( algorithm= 'SAMME.R', learning_rate= 1, n_estimators= 1000, random_state = 1)\n",
    "ada_boost.fit(x_train, np.ravel(y_train))\n",
    "y_pred_ada_boost = ada_boost.predict(x_test)\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_ada_boost))\n",
    "print(\"Precision:\", metrics.precision_score(y_test, y_pred_ada_boost))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred_ada_boost))\n",
    "print(\"F1_score:\", metrics.f1_score(y_test, y_pred_ada_boost))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
