{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\haven\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\haven\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\haven\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\haven\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "import keras\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout, Activation, Embedding\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from keras.utils import pad_sequences\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "wnl = WordNetLemmatizer() # wnl.lemmatize(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>text_without_stopwords</th>\n",
       "      <th>title_without_stopwords</th>\n",
       "      <th>text_word_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>text_sentence_count</th>\n",
       "      <th>title_sentence_count</th>\n",
       "      <th>text_average_word_length</th>\n",
       "      <th>...</th>\n",
       "      <th>polarity</th>\n",
       "      <th>overall_content</th>\n",
       "      <th>Topic 1 Probability</th>\n",
       "      <th>Topic 2 Probability</th>\n",
       "      <th>Topic 3 Probbility</th>\n",
       "      <th>Topic 4 Probability</th>\n",
       "      <th>Topic 5 Probability</th>\n",
       "      <th>polarity_category</th>\n",
       "      <th>polarity_category_Neutral</th>\n",
       "      <th>polarity_category_Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>1</td>\n",
       "      <td>donald trump wish americans happy new year lea...</td>\n",
       "      <td>donald trump sends out embarrassing new year’s...</td>\n",
       "      <td>516</td>\n",
       "      <td>13</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>4.804040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082132</td>\n",
       "      <td>donald trump sends out embarrassing new year’s...</td>\n",
       "      <td>0.002194</td>\n",
       "      <td>0.747636</td>\n",
       "      <td>0.001007</td>\n",
       "      <td>0.157660</td>\n",
       "      <td>0.091503</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>1</td>\n",
       "      <td>house intelligence committee chairman devin nu...</td>\n",
       "      <td>drunk bragging trump staffer started russian c...</td>\n",
       "      <td>309</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>5.213115</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005004</td>\n",
       "      <td>drunk bragging trump staffer started russian c...</td>\n",
       "      <td>0.064904</td>\n",
       "      <td>0.244962</td>\n",
       "      <td>0.557051</td>\n",
       "      <td>0.002320</td>\n",
       "      <td>0.130763</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>1</td>\n",
       "      <td>on friday revealed former milwaukee sheriff da...</td>\n",
       "      <td>sheriff david clarke becomes an internet joke ...</td>\n",
       "      <td>600</td>\n",
       "      <td>16</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>5.168966</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012345</td>\n",
       "      <td>sheriff david clarke becomes an internet joke ...</td>\n",
       "      <td>0.002488</td>\n",
       "      <td>0.433611</td>\n",
       "      <td>0.281460</td>\n",
       "      <td>0.001917</td>\n",
       "      <td>0.280524</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "      <td>1</td>\n",
       "      <td>on christmas day donald trump announced would ...</td>\n",
       "      <td>trump is so obsessed he even has obama’s name ...</td>\n",
       "      <td>475</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>5.180180</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023118</td>\n",
       "      <td>trump is so obsessed he even has obama’s name ...</td>\n",
       "      <td>0.002963</td>\n",
       "      <td>0.788261</td>\n",
       "      <td>0.204377</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>0.002109</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "      <td>1</td>\n",
       "      <td>pope francis used annual christmas day message...</td>\n",
       "      <td>pope francis just called out donald trump duri...</td>\n",
       "      <td>434</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>4.554762</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011722</td>\n",
       "      <td>pope francis just called out donald trump duri...</td>\n",
       "      <td>0.292172</td>\n",
       "      <td>0.327938</td>\n",
       "      <td>0.001138</td>\n",
       "      <td>0.020911</td>\n",
       "      <td>0.357842</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
       "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
       "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
       "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
       "\n",
       "                                                text  class  \\\n",
       "0  Donald Trump just couldn t wish all Americans ...      1   \n",
       "1  House Intelligence Committee Chairman Devin Nu...      1   \n",
       "2  On Friday, it was revealed that former Milwauk...      1   \n",
       "3  On Christmas day, Donald Trump announced that ...      1   \n",
       "4  Pope Francis used his annual Christmas Day mes...      1   \n",
       "\n",
       "                              text_without_stopwords  \\\n",
       "0  donald trump wish americans happy new year lea...   \n",
       "1  house intelligence committee chairman devin nu...   \n",
       "2  on friday revealed former milwaukee sheriff da...   \n",
       "3  on christmas day donald trump announced would ...   \n",
       "4  pope francis used annual christmas day message...   \n",
       "\n",
       "                             title_without_stopwords  text_word_count  \\\n",
       "0  donald trump sends out embarrassing new year’s...              516   \n",
       "1  drunk bragging trump staffer started russian c...              309   \n",
       "2  sheriff david clarke becomes an internet joke ...              600   \n",
       "3  trump is so obsessed he even has obama’s name ...              475   \n",
       "4  pope francis just called out donald trump duri...              434   \n",
       "\n",
       "   title_word_count  text_sentence_count  title_sentence_count  \\\n",
       "0                13                   28                     1   \n",
       "1                 9                   11                     1   \n",
       "2                16                   25                     1   \n",
       "3                15                   15                     1   \n",
       "4                12                   19                     1   \n",
       "\n",
       "   text_average_word_length  ...  polarity  \\\n",
       "0                  4.804040  ...  0.082132   \n",
       "1                  5.213115  ... -0.005004   \n",
       "2                  5.168966  ... -0.012345   \n",
       "3                  5.180180  ... -0.023118   \n",
       "4                  4.554762  ... -0.011722   \n",
       "\n",
       "                                     overall_content  Topic 1 Probability  \\\n",
       "0  donald trump sends out embarrassing new year’s...             0.002194   \n",
       "1  drunk bragging trump staffer started russian c...             0.064904   \n",
       "2  sheriff david clarke becomes an internet joke ...             0.002488   \n",
       "3  trump is so obsessed he even has obama’s name ...             0.002963   \n",
       "4  pope francis just called out donald trump duri...             0.292172   \n",
       "\n",
       "   Topic 2 Probability  Topic 3 Probbility  Topic 4 Probability  \\\n",
       "0             0.747636            0.001007             0.157660   \n",
       "1             0.244962            0.557051             0.002320   \n",
       "2             0.433611            0.281460             0.001917   \n",
       "3             0.788261            0.204377             0.002290   \n",
       "4             0.327938            0.001138             0.020911   \n",
       "\n",
       "   Topic 5 Probability  polarity_category  polarity_category_Neutral  \\\n",
       "0             0.091503           Positive                          0   \n",
       "1             0.130763            Neutral                          1   \n",
       "2             0.280524            Neutral                          1   \n",
       "3             0.002109            Neutral                          1   \n",
       "4             0.357842            Neutral                          1   \n",
       "\n",
       "  polarity_category_Positive  \n",
       "0                          1  \n",
       "1                          0  \n",
       "2                          0  \n",
       "3                          0  \n",
       "4                          0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"processed_data.csv\") # shld be preprocessed data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observe which data types to use\n",
    "dt = pd.DataFrame(data.dtypes).reset_index()\n",
    "data_numerics = dt[dt[0].isin([np.dtype('int64'), np.dtype('float64')])]\n",
    "data_text = dt[dt[0].isin([np.dtype('object')])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>title</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>text</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>class</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>text_without_stopwords</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>title_without_stopwords</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>text_word_count</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>title_word_count</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>text_sentence_count</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>title_sentence_count</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>text_average_word_length</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>title_average_word_length</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>text_punctuation_count</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>title_punctuation_count</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>text_stopwords_count</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>title_stopwords_count</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>syllables</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>flesch_readability</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>subjectivity</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>polarity</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>overall_content</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Topic 1 Probability</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Topic 2 Probability</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Topic 3 Probbility</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Topic 4 Probability</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Topic 5 Probability</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>polarity_category</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>polarity_category_Neutral</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>polarity_category_Positive</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         index        0\n",
       "0                        title   object\n",
       "1                         text   object\n",
       "2                        class    int64\n",
       "3       text_without_stopwords   object\n",
       "4      title_without_stopwords   object\n",
       "5              text_word_count    int64\n",
       "6             title_word_count    int64\n",
       "7          text_sentence_count    int64\n",
       "8         title_sentence_count    int64\n",
       "9     text_average_word_length  float64\n",
       "10   title_average_word_length  float64\n",
       "11      text_punctuation_count    int64\n",
       "12     title_punctuation_count    int64\n",
       "13        text_stopwords_count    int64\n",
       "14       title_stopwords_count    int64\n",
       "15                   syllables    int64\n",
       "16          flesch_readability  float64\n",
       "17                subjectivity  float64\n",
       "18                    polarity  float64\n",
       "19             overall_content   object\n",
       "20         Topic 1 Probability  float64\n",
       "21         Topic 2 Probability  float64\n",
       "22          Topic 3 Probbility  float64\n",
       "23         Topic 4 Probability  float64\n",
       "24         Topic 5 Probability  float64\n",
       "25           polarity_category   object\n",
       "26   polarity_category_Neutral    int64\n",
       "27  polarity_category_Positive    int64"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>class</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>text_word_count</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>title_word_count</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>text_sentence_count</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>title_sentence_count</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>text_average_word_length</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>title_average_word_length</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>text_punctuation_count</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>title_punctuation_count</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>text_stopwords_count</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>title_stopwords_count</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>syllables</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>flesch_readability</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>subjectivity</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>polarity</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Topic 1 Probability</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Topic 2 Probability</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Topic 3 Probbility</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Topic 4 Probability</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Topic 5 Probability</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>polarity_category_Neutral</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>polarity_category_Positive</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         index        0\n",
       "2                        class    int64\n",
       "5              text_word_count    int64\n",
       "6             title_word_count    int64\n",
       "7          text_sentence_count    int64\n",
       "8         title_sentence_count    int64\n",
       "9     text_average_word_length  float64\n",
       "10   title_average_word_length  float64\n",
       "11      text_punctuation_count    int64\n",
       "12     title_punctuation_count    int64\n",
       "13        text_stopwords_count    int64\n",
       "14       title_stopwords_count    int64\n",
       "15                   syllables    int64\n",
       "16          flesch_readability  float64\n",
       "17                subjectivity  float64\n",
       "18                    polarity  float64\n",
       "20         Topic 1 Probability  float64\n",
       "21         Topic 2 Probability  float64\n",
       "22          Topic 3 Probbility  float64\n",
       "23         Topic 4 Probability  float64\n",
       "24         Topic 5 Probability  float64\n",
       "26   polarity_category_Neutral    int64\n",
       "27  polarity_category_Positive    int64"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_numerics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>title</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>text</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>text_without_stopwords</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>title_without_stopwords</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>overall_content</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>polarity_category</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      index       0\n",
       "0                     title  object\n",
       "1                      text  object\n",
       "3    text_without_stopwords  object\n",
       "4   title_without_stopwords  object\n",
       "19          overall_content  object\n",
       "25        polarity_category  object"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state = 0)\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y split of training data\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[list(data_numerics['index'])[1:]], data['class'], test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores, pvalues = chi2(abs(X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X2</th>\n",
       "      <th>pvalues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>flesch_readability</td>\n",
       "      <td>4.701484e-267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Topic 4 Probability</td>\n",
       "      <td>4.124591e-150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>title_punctuation_count</td>\n",
       "      <td>2.891466e-88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Topic 5 Probability</td>\n",
       "      <td>7.830582e-53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>text_sentence_count</td>\n",
       "      <td>5.665991e-39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>subjectivity</td>\n",
       "      <td>4.585605e-35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>title_sentence_count</td>\n",
       "      <td>1.253078e-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>title_average_word_length</td>\n",
       "      <td>2.496743e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>polarity_category_Neutral</td>\n",
       "      <td>2.070811e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Topic 3 Probbility</td>\n",
       "      <td>2.602930e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>polarity</td>\n",
       "      <td>1.731023e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>polarity_category_Positive</td>\n",
       "      <td>1.935275e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>text_average_word_length</td>\n",
       "      <td>1.642177e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            X2        pvalues\n",
       "11          flesch_readability  4.701484e-267\n",
       "17         Topic 4 Probability  4.124591e-150\n",
       "7      title_punctuation_count   2.891466e-88\n",
       "18         Topic 5 Probability   7.830582e-53\n",
       "2          text_sentence_count   5.665991e-39\n",
       "12                subjectivity   4.585605e-35\n",
       "3         title_sentence_count   1.253078e-26\n",
       "5    title_average_word_length   2.496743e-12\n",
       "19   polarity_category_Neutral   2.070811e-11\n",
       "16          Topic 3 Probbility   2.602930e-07\n",
       "13                    polarity   1.731023e-05\n",
       "20  polarity_category_Positive   1.935275e-03\n",
       "4     text_average_word_length   1.642177e-02"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "com_dic = {'X2':X_train.columns, 'pvalues':pvalues}\n",
    "result = pd.DataFrame(com_dic).sort_values(['pvalues'])\n",
    "result[result['pvalues'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haven\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\haven\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy (%)</th>\n",
       "      <th>Precision (%)</th>\n",
       "      <th>Recall (%)</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>44.749095</td>\n",
       "      <td>44.749095</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.618299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy (%)  Precision (%)  Recall (%)  F1 Score\n",
       "0  Logistic Regression     44.749095      44.749095       100.0  0.618299"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "lr_fit = lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "precision = precision_score(y_test, y_pred) * 100\n",
    "recall = recall_score(y_test, y_pred) * 100\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "results = pd.DataFrame({\"Model\": 'Logistic Regression',\n",
    "                        \"Accuracy (%)\": [accuracy], \n",
    "                        \"Precision (%)\": [precision], \n",
    "                        \"Recall (%)\": [recall], \n",
    "                        \"F1 Score\": [f1]})\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.50681320e+00  3.02285916e+01 -9.92060388e+00  5.01433581e+00\n",
      "   2.43653672e+00  1.20290388e+00  1.03369538e+00 -2.90890911e+00\n",
      "   7.82192573e+00 -2.07183385e+01  1.30133690e+00 -3.67836225e+00\n",
      "   2.43170470e+00  2.60102591e-02 -3.13620495e+00  2.47826891e+00\n",
      "   5.33627962e-01 -1.42147622e+00  1.35488863e+00 -3.91578783e-02\n",
      "  -8.45008722e-02]] [-3.87769963]\n"
     ]
    }
   ],
   "source": [
    "print(lr.coef_, lr.intercept_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haven\\AppData\\Local\\Temp\\ipykernel_7196\\1409134553.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fake['title_without_stopwords']  = fake['title_without_stopwords'].apply(lambda t: re.sub('[^a-z0-9]', ' ', t))\n",
      "C:\\Users\\haven\\AppData\\Local\\Temp\\ipykernel_7196\\1409134553.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fake['title_without_stopwords'] = fake['title_without_stopwords'].apply(lambda t: wnl.lemmatize(t))\n",
      "C:\\Users\\haven\\AppData\\Local\\Temp\\ipykernel_7196\\1409134553.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  real['title_without_stopwords']  = real['title_without_stopwords'].apply(lambda t: re.sub('[^a-z0-9]', ' ', t))\n",
      "C:\\Users\\haven\\AppData\\Local\\Temp\\ipykernel_7196\\1409134553.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  real['title_without_stopwords'] = real['title_without_stopwords'].apply(lambda t: wnl.lemmatize(t))\n",
      "C:\\Users\\haven\\AppData\\Local\\Temp\\ipykernel_7196\\1409134553.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fake['title_tokenized'] = data['title_without_stopwords'].apply(lambda t: word_tokenize(t))\n",
      "C:\\Users\\haven\\AppData\\Local\\Temp\\ipykernel_7196\\1409134553.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  real['title_tokenized'] = real['title_without_stopwords'].apply(lambda t: word_tokenize(t))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.153384</td>\n",
       "      <td>0.157413</td>\n",
       "      <td>-0.022656</td>\n",
       "      <td>0.037219</td>\n",
       "      <td>0.027063</td>\n",
       "      <td>-0.177757</td>\n",
       "      <td>0.018690</td>\n",
       "      <td>0.226300</td>\n",
       "      <td>-0.201620</td>\n",
       "      <td>-0.133207</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034678</td>\n",
       "      <td>0.022188</td>\n",
       "      <td>0.109311</td>\n",
       "      <td>0.187424</td>\n",
       "      <td>0.105319</td>\n",
       "      <td>0.045469</td>\n",
       "      <td>-0.129377</td>\n",
       "      <td>0.039450</td>\n",
       "      <td>0.047787</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.006082</td>\n",
       "      <td>0.096959</td>\n",
       "      <td>-0.186203</td>\n",
       "      <td>0.054901</td>\n",
       "      <td>-0.008691</td>\n",
       "      <td>-0.046646</td>\n",
       "      <td>0.127368</td>\n",
       "      <td>0.274909</td>\n",
       "      <td>-0.131535</td>\n",
       "      <td>0.019971</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173057</td>\n",
       "      <td>0.116074</td>\n",
       "      <td>0.161901</td>\n",
       "      <td>0.219141</td>\n",
       "      <td>0.058383</td>\n",
       "      <td>-0.006335</td>\n",
       "      <td>-0.195945</td>\n",
       "      <td>-0.143082</td>\n",
       "      <td>-0.056557</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.132909</td>\n",
       "      <td>0.102688</td>\n",
       "      <td>0.043570</td>\n",
       "      <td>0.130463</td>\n",
       "      <td>0.095260</td>\n",
       "      <td>-0.089076</td>\n",
       "      <td>0.075465</td>\n",
       "      <td>0.194728</td>\n",
       "      <td>-0.070718</td>\n",
       "      <td>-0.136775</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036136</td>\n",
       "      <td>0.120661</td>\n",
       "      <td>0.089220</td>\n",
       "      <td>0.192577</td>\n",
       "      <td>0.068442</td>\n",
       "      <td>0.046079</td>\n",
       "      <td>-0.070680</td>\n",
       "      <td>-0.053058</td>\n",
       "      <td>-0.053955</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.076484</td>\n",
       "      <td>0.124307</td>\n",
       "      <td>-0.006773</td>\n",
       "      <td>0.063440</td>\n",
       "      <td>-0.007710</td>\n",
       "      <td>-0.183439</td>\n",
       "      <td>0.045770</td>\n",
       "      <td>0.258358</td>\n",
       "      <td>-0.118497</td>\n",
       "      <td>-0.114814</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.107686</td>\n",
       "      <td>0.048167</td>\n",
       "      <td>0.083651</td>\n",
       "      <td>0.132422</td>\n",
       "      <td>0.058325</td>\n",
       "      <td>0.053401</td>\n",
       "      <td>-0.065312</td>\n",
       "      <td>-0.002653</td>\n",
       "      <td>0.005582</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.115217</td>\n",
       "      <td>0.121326</td>\n",
       "      <td>-0.059588</td>\n",
       "      <td>0.053643</td>\n",
       "      <td>0.055595</td>\n",
       "      <td>-0.176988</td>\n",
       "      <td>0.054526</td>\n",
       "      <td>0.261345</td>\n",
       "      <td>-0.192073</td>\n",
       "      <td>-0.129673</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.082523</td>\n",
       "      <td>0.018045</td>\n",
       "      <td>0.096476</td>\n",
       "      <td>0.170662</td>\n",
       "      <td>0.063639</td>\n",
       "      <td>0.045130</td>\n",
       "      <td>-0.091450</td>\n",
       "      <td>0.072571</td>\n",
       "      <td>0.042612</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.153384  0.157413 -0.022656  0.037219  0.027063 -0.177757  0.018690   \n",
       "1 -0.006082  0.096959 -0.186203  0.054901 -0.008691 -0.046646  0.127368   \n",
       "2  0.132909  0.102688  0.043570  0.130463  0.095260 -0.089076  0.075465   \n",
       "3 -0.076484  0.124307 -0.006773  0.063440 -0.007710 -0.183439  0.045770   \n",
       "4 -0.115217  0.121326 -0.059588  0.053643  0.055595 -0.176988  0.054526   \n",
       "\n",
       "        7         8         9    ...       91        92        93        94   \\\n",
       "0  0.226300 -0.201620 -0.133207  ... -0.034678  0.022188  0.109311  0.187424   \n",
       "1  0.274909 -0.131535  0.019971  ...  0.173057  0.116074  0.161901  0.219141   \n",
       "2  0.194728 -0.070718 -0.136775  ...  0.036136  0.120661  0.089220  0.192577   \n",
       "3  0.258358 -0.118497 -0.114814  ... -0.107686  0.048167  0.083651  0.132422   \n",
       "4  0.261345 -0.192073 -0.129673  ... -0.082523  0.018045  0.096476  0.170662   \n",
       "\n",
       "        95        96        97        98        99   100  \n",
       "0  0.105319  0.045469 -0.129377  0.039450  0.047787  0.0  \n",
       "1  0.058383 -0.006335 -0.195945 -0.143082 -0.056557  1.0  \n",
       "2  0.068442  0.046079 -0.070680 -0.053058 -0.053955  1.0  \n",
       "3  0.058325  0.053401 -0.065312 -0.002653  0.005582  0.0  \n",
       "4  0.063639  0.045130 -0.091450  0.072571  0.042612  0.0  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Split the data into real and fake, apply word2vec each, apply class and combine\n",
    "\"\"\"\n",
    "fake = data[data['class'] == 1]\n",
    "real = data[data['class'] == 0]\n",
    "\n",
    "# Linguistic Processing\n",
    "fake['title_without_stopwords']  = fake['title_without_stopwords'].apply(lambda t: re.sub('[^a-z0-9]', ' ', t))\n",
    "fake['title_without_stopwords'] = fake['title_without_stopwords'].apply(lambda t: wnl.lemmatize(t))\n",
    "\n",
    "real['title_without_stopwords']  = real['title_without_stopwords'].apply(lambda t: re.sub('[^a-z0-9]', ' ', t))\n",
    "real['title_without_stopwords'] = real['title_without_stopwords'].apply(lambda t: wnl.lemmatize(t))\n",
    "\n",
    "# Tokenize\n",
    "fake['title_tokenized'] = data['title_without_stopwords'].apply(lambda t: word_tokenize(t))\n",
    "real['title_tokenized'] = real['title_without_stopwords'].apply(lambda t: word_tokenize(t))\n",
    "\n",
    "# Embedding\n",
    "fake_model = Word2Vec(fake['title_tokenized'], min_count=1)\n",
    "real_model = Word2Vec(real['title_tokenized'], min_count=1)\n",
    "\n",
    "# Get Norm Vectors\n",
    "fake_vect = fake_model.wv.get_normed_vectors()\n",
    "real_vect = real_model.wv.get_normed_vectors()\n",
    "\n",
    "# Add class\n",
    "fake_vect = [np.concatenate((vec,[1])) for vec in fake_vect]\n",
    "real_vect = [np.concatenate((vec,[0])) for vec in real_vect]\n",
    "\n",
    "fake_vect.extend(real_vect)\n",
    "random.shuffle(fake_vect)\n",
    "vect_pd = pd.DataFrame(fake_vect)\n",
    "vect_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data: \n",
      "(25918, 100)\n",
      "(25918,)\n",
      "Shape of test data: \n",
      "(6480, 100)\n",
      "(6480,)\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 100, 32)           224000    \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 100, 32)           3104      \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 50, 32)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 250)               400250    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 251       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 627,605\n",
      "Trainable params: 627,605\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/2\n",
      "203/203 - 6s - loss: 0.6802 - accuracy: 0.5819 - 6s/epoch - 29ms/step\n",
      "Epoch 2/2\n",
      "203/203 - 4s - loss: 0.6801 - accuracy: 0.5830 - 4s/epoch - 17ms/step\n",
      "Accuracy: 57.65%\n"
     ]
    }
   ],
   "source": [
    "# Our dictionary will contain only of the top 7000 words appearing most frequently\n",
    "top_words = 7000\n",
    "\n",
    "# Now we split our data-set into training and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(vect_pd.iloc[:, :-1], vect_pd.iloc[:, -1], test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Looking at the nature of training data\n",
    "print('Shape of training data: ')\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print('Shape of test data: ')\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# Padding the data samples to a maximum review length in words\n",
    "max_words = 450\n",
    "\n",
    "# Remove stopwords, punctuation, lemmatize, before Word2Vec\n",
    "\n",
    "#X_train = pad_sequences(X_train, maxlen=max_words)\n",
    "#X_test = pad_sequences(X_test, maxlen=max_words)\n",
    "\n",
    "# Building the CNN Model\n",
    "model = Sequential()      # initilaizing the Sequential nature for CNN model\n",
    "\n",
    "# Adding the embedding layer which will take in maximum of 450 words as input and provide a 32 dimensional output of those words which belong in the top_words dictionary\n",
    "model.add(Embedding(top_words, 32, input_length=100))\n",
    "model.add(Conv1D(32, 3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.build()\n",
    "model.summary()\n",
    "\n",
    "# Fitting the data onto model\n",
    "model.fit(X_train, y_train, epochs=2, batch_size=128, verbose=2)\n",
    "\n",
    "# Getting score metrics from our model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "# Displays the accuracy of correct sentiment prediction over test data\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
