{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from keras.layers import TextVectorization, Dense, Conv1D, Embedding, Dropout, GlobalMaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>text_without_stopwords</th>\n",
       "      <th>title_without_stopwords</th>\n",
       "      <th>text_word_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>text_sentence_count</th>\n",
       "      <th>title_sentence_count</th>\n",
       "      <th>text_average_word_length</th>\n",
       "      <th>...</th>\n",
       "      <th>polarity</th>\n",
       "      <th>overall_content</th>\n",
       "      <th>Topic 1 Probability</th>\n",
       "      <th>Topic 2 Probability</th>\n",
       "      <th>Topic 3 Probbility</th>\n",
       "      <th>Topic 4 Probability</th>\n",
       "      <th>Topic 5 Probability</th>\n",
       "      <th>polarity_category</th>\n",
       "      <th>polarity_category_Neutral</th>\n",
       "      <th>polarity_category_Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>1</td>\n",
       "      <td>donald trump wish americans happy new year lea...</td>\n",
       "      <td>donald trump sends out embarrassing new year’s...</td>\n",
       "      <td>516</td>\n",
       "      <td>13</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>4.804040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082132</td>\n",
       "      <td>donald trump sends out embarrassing new year’s...</td>\n",
       "      <td>0.002194</td>\n",
       "      <td>0.747636</td>\n",
       "      <td>0.001007</td>\n",
       "      <td>0.157660</td>\n",
       "      <td>0.091503</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>1</td>\n",
       "      <td>house intelligence committee chairman devin nu...</td>\n",
       "      <td>drunk bragging trump staffer started russian c...</td>\n",
       "      <td>309</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>5.213115</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005004</td>\n",
       "      <td>drunk bragging trump staffer started russian c...</td>\n",
       "      <td>0.064904</td>\n",
       "      <td>0.244962</td>\n",
       "      <td>0.557051</td>\n",
       "      <td>0.002320</td>\n",
       "      <td>0.130763</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>1</td>\n",
       "      <td>on friday revealed former milwaukee sheriff da...</td>\n",
       "      <td>sheriff david clarke becomes an internet joke ...</td>\n",
       "      <td>600</td>\n",
       "      <td>16</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>5.168966</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012345</td>\n",
       "      <td>sheriff david clarke becomes an internet joke ...</td>\n",
       "      <td>0.002488</td>\n",
       "      <td>0.433611</td>\n",
       "      <td>0.281460</td>\n",
       "      <td>0.001917</td>\n",
       "      <td>0.280524</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "      <td>1</td>\n",
       "      <td>on christmas day donald trump announced would ...</td>\n",
       "      <td>trump is so obsessed he even has obama’s name ...</td>\n",
       "      <td>475</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>5.180180</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023118</td>\n",
       "      <td>trump is so obsessed he even has obama’s name ...</td>\n",
       "      <td>0.002963</td>\n",
       "      <td>0.788261</td>\n",
       "      <td>0.204377</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>0.002109</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "      <td>1</td>\n",
       "      <td>pope francis used annual christmas day message...</td>\n",
       "      <td>pope francis just called out donald trump duri...</td>\n",
       "      <td>434</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>4.554762</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011722</td>\n",
       "      <td>pope francis just called out donald trump duri...</td>\n",
       "      <td>0.292172</td>\n",
       "      <td>0.327938</td>\n",
       "      <td>0.001138</td>\n",
       "      <td>0.020911</td>\n",
       "      <td>0.357842</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
       "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
       "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
       "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
       "\n",
       "                                                text  class  \\\n",
       "0  Donald Trump just couldn t wish all Americans ...      1   \n",
       "1  House Intelligence Committee Chairman Devin Nu...      1   \n",
       "2  On Friday, it was revealed that former Milwauk...      1   \n",
       "3  On Christmas day, Donald Trump announced that ...      1   \n",
       "4  Pope Francis used his annual Christmas Day mes...      1   \n",
       "\n",
       "                              text_without_stopwords  \\\n",
       "0  donald trump wish americans happy new year lea...   \n",
       "1  house intelligence committee chairman devin nu...   \n",
       "2  on friday revealed former milwaukee sheriff da...   \n",
       "3  on christmas day donald trump announced would ...   \n",
       "4  pope francis used annual christmas day message...   \n",
       "\n",
       "                             title_without_stopwords  text_word_count  \\\n",
       "0  donald trump sends out embarrassing new year’s...              516   \n",
       "1  drunk bragging trump staffer started russian c...              309   \n",
       "2  sheriff david clarke becomes an internet joke ...              600   \n",
       "3  trump is so obsessed he even has obama’s name ...              475   \n",
       "4  pope francis just called out donald trump duri...              434   \n",
       "\n",
       "   title_word_count  text_sentence_count  title_sentence_count  \\\n",
       "0                13                   28                     1   \n",
       "1                 9                   11                     1   \n",
       "2                16                   25                     1   \n",
       "3                15                   15                     1   \n",
       "4                12                   19                     1   \n",
       "\n",
       "   text_average_word_length  ...  polarity  \\\n",
       "0                  4.804040  ...  0.082132   \n",
       "1                  5.213115  ... -0.005004   \n",
       "2                  5.168966  ... -0.012345   \n",
       "3                  5.180180  ... -0.023118   \n",
       "4                  4.554762  ... -0.011722   \n",
       "\n",
       "                                     overall_content  Topic 1 Probability  \\\n",
       "0  donald trump sends out embarrassing new year’s...             0.002194   \n",
       "1  drunk bragging trump staffer started russian c...             0.064904   \n",
       "2  sheriff david clarke becomes an internet joke ...             0.002488   \n",
       "3  trump is so obsessed he even has obama’s name ...             0.002963   \n",
       "4  pope francis just called out donald trump duri...             0.292172   \n",
       "\n",
       "   Topic 2 Probability  Topic 3 Probbility  Topic 4 Probability  \\\n",
       "0             0.747636            0.001007             0.157660   \n",
       "1             0.244962            0.557051             0.002320   \n",
       "2             0.433611            0.281460             0.001917   \n",
       "3             0.788261            0.204377             0.002290   \n",
       "4             0.327938            0.001138             0.020911   \n",
       "\n",
       "   Topic 5 Probability  polarity_category  polarity_category_Neutral  \\\n",
       "0             0.091503           Positive                          0   \n",
       "1             0.130763            Neutral                          1   \n",
       "2             0.280524            Neutral                          1   \n",
       "3             0.002109            Neutral                          1   \n",
       "4             0.357842            Neutral                          1   \n",
       "\n",
       "  polarity_category_Positive  \n",
       "0                          1  \n",
       "1                          0  \n",
       "2                          0  \n",
       "3                          0  \n",
       "4                          0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"processed_data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first split the dataset into training and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(data['overall_content'], data['class'], test_size = 0.2, random_state = 4222)\n",
    "\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(x_train, y_train, test_size = 0.25, random_state = 4222)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches in raw_train_ds: 725\n",
      "Number of batches in raw_val_ds: 242\n",
      "Number of batches in raw_test_ds: 242\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "raw_train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (tf.constant(x_train.squeeze().to_list()),\n",
    "     tf.keras.utils.to_categorical(y_train.to_numpy() -1))\n",
    ").batch(batch_size)\n",
    "\n",
    "raw_test_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (tf.constant(x_test.squeeze().to_list()),\n",
    "     tf.keras.utils.to_categorical(y_test.to_numpy() -1))\n",
    ").batch(batch_size)\n",
    "\n",
    "raw_val_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (tf.constant(x_validation.squeeze().to_list()),\n",
    "     tf.keras.utils.to_categorical(y_validation.to_numpy() -1))\n",
    ").batch(batch_size)\n",
    "\n",
    "print(f\"Number of batches in raw_train_ds: {raw_train_ds.cardinality()}\")\n",
    "print(f\"Number of batches in raw_val_ds: {raw_val_ds.cardinality()}\")\n",
    "print(f\"Number of batches in raw_test_ds: {raw_test_ds.cardinality()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model constants.\n",
    "max_features = 20000\n",
    "embedding_dim = 128\n",
    "sequence_length = 500\n",
    "\n",
    "vectorize_layer = TextVectorization(\n",
    "    standardize='lower_and_strip_punctuation',\n",
    "    max_tokens=max_features,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length,\n",
    ")\n",
    "\n",
    "# Let's make a text-only dataset (no labels):\n",
    "text_ds = raw_train_ds.map(lambda x, _ : x)\n",
    "# Let's call `adapt`:\n",
    "vectorize_layer.adapt(text_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(text, label):\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    return vectorize_layer(text), label\n",
    "\n",
    "# Vectorize the data.\n",
    "train_ds = raw_train_ds.map(vectorize_text)\n",
    "val_ds = raw_val_ds.map(vectorize_text)\n",
    "test_ds = raw_test_ds.map(vectorize_text)\n",
    "\n",
    "# Do async prefetching / buffering of the data for best performance on GPU.\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=10)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=10)\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "# Next, we add a layer to map those vocab indices into a space of dimensionality 'embedding_dim'.\n",
    "model.add(Embedding(max_features, embedding_dim))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Conv1D + global max pooling\n",
    "model.add(Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3))\n",
    "model.add(Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "\n",
    "# We add a vanilla hidden layer:\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# We project onto a single unit output layer, and squash it with a sigmoid:\n",
    "model.add(Dense(1, activation=\"sigmoid\", name=\"predictions\"))\n",
    "\n",
    "# Compile the model with binary crossentropy loss and an adam optimizer.\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 128)         2560000   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, None, 128)         0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, None, 128)         114816    \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, None, 128)         114816    \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 128)              0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,806,273\n",
      "Trainable params: 2,806,273\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "725/725 [==============================] - 93s 125ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 1.8122e-07 - val_accuracy: 1.0000\n",
      "Epoch 2/2\n",
      "725/725 [==============================] - 90s 124ms/step - loss: 6.1653e-07 - accuracy: 1.0000 - val_loss: 5.1610e-08 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x223cc3c2b50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 2\n",
    "\n",
    "# Fit the model using the train and test datasets.\n",
    "model.fit(train_ds, validation_data=val_ds, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 4s 15ms/step - loss: 5.3096e-08 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.309597028713142e-08, 1.0]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ce9f17b5bd105c5507d96ff01fabfb6af60c48b139833c32487c7fda2c0d6fef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
