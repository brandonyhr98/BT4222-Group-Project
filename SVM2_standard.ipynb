{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split , GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"master_dataset/processed_data.csv\")\n",
    "list(data.columns)\n",
    "# drop unwanted features\n",
    "\n",
    "\n",
    "data = data.drop(['title', 'text', 'text_without_stopwords', 'title_without_stopwords','syllables', \n",
    "                  'polarity_category', 'overall_content', 'polarity_category_Neutral' , 'polarity_category_Positive',\n",
    "                  'text_average_word_length',  'title_average_word_length',  'text_punctuation_count',\n",
    "                    'title_punctuation_count',  'text_stopwords_count',  'title_stopwords_count',], axis=1)\n",
    "\n",
    "#'title_word_count', 'title_sentence_count', 'title_average_word_length','title_punctuation_count', 'title_stopwords_count'  \n",
    "# 'polarity'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    21196\n",
       "1    17462\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataset is slightly imbalanced so we will perform upsampling to balance the dataset.\n",
    "data['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['class',\n",
       " 'text_word_count',\n",
       " 'title_word_count',\n",
       " 'text_sentence_count',\n",
       " 'title_sentence_count',\n",
       " 'flesch_readability',\n",
       " 'subjectivity',\n",
       " 'polarity',\n",
       " 'Topic 1 Probability',\n",
       " 'Topic 2 Probability',\n",
       " 'Topic 3 Probbility',\n",
       " 'Topic 4 Probability',\n",
       " 'Topic 5 Probability']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text_word_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>text_sentence_count</th>\n",
       "      <th>title_sentence_count</th>\n",
       "      <th>flesch_readability</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>polarity</th>\n",
       "      <th>Topic 1 Probability</th>\n",
       "      <th>Topic 2 Probability</th>\n",
       "      <th>Topic 3 Probbility</th>\n",
       "      <th>Topic 4 Probability</th>\n",
       "      <th>Topic 5 Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>38658.000000</td>\n",
       "      <td>38658.000000</td>\n",
       "      <td>38658.000000</td>\n",
       "      <td>38658.000000</td>\n",
       "      <td>38658.000000</td>\n",
       "      <td>38658.000000</td>\n",
       "      <td>38658.000000</td>\n",
       "      <td>38658.000000</td>\n",
       "      <td>38658.000000</td>\n",
       "      <td>38658.000000</td>\n",
       "      <td>38658.000000</td>\n",
       "      <td>38658.000000</td>\n",
       "      <td>38658.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.451705</td>\n",
       "      <td>411.374515</td>\n",
       "      <td>12.161209</td>\n",
       "      <td>15.050830</td>\n",
       "      <td>1.067877</td>\n",
       "      <td>0.006674</td>\n",
       "      <td>0.402753</td>\n",
       "      <td>0.056997</td>\n",
       "      <td>0.190953</td>\n",
       "      <td>0.324903</td>\n",
       "      <td>0.125233</td>\n",
       "      <td>0.185360</td>\n",
       "      <td>0.173552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.497669</td>\n",
       "      <td>322.881353</td>\n",
       "      <td>3.765686</td>\n",
       "      <td>11.985707</td>\n",
       "      <td>0.270277</td>\n",
       "      <td>1.003826</td>\n",
       "      <td>0.124806</td>\n",
       "      <td>0.105170</td>\n",
       "      <td>0.281023</td>\n",
       "      <td>0.312565</td>\n",
       "      <td>0.210573</td>\n",
       "      <td>0.258829</td>\n",
       "      <td>0.234861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-83.616811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.000268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.169506</td>\n",
       "      <td>0.337127</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002949</td>\n",
       "      <td>0.010969</td>\n",
       "      <td>0.001305</td>\n",
       "      <td>0.003113</td>\n",
       "      <td>0.003024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>376.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.050549</td>\n",
       "      <td>0.405745</td>\n",
       "      <td>0.054757</td>\n",
       "      <td>0.030471</td>\n",
       "      <td>0.231605</td>\n",
       "      <td>0.006765</td>\n",
       "      <td>0.056382</td>\n",
       "      <td>0.056373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>522.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.267479</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.108144</td>\n",
       "      <td>0.282926</td>\n",
       "      <td>0.584998</td>\n",
       "      <td>0.157612</td>\n",
       "      <td>0.272065</td>\n",
       "      <td>0.268291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>8436.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>321.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.614284</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997819</td>\n",
       "      <td>0.998037</td>\n",
       "      <td>0.996771</td>\n",
       "      <td>0.998911</td>\n",
       "      <td>0.998767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              class  text_word_count  title_word_count  text_sentence_count  \\\n",
       "count  38658.000000     38658.000000      38658.000000         38658.000000   \n",
       "mean       0.451705       411.374515         12.161209            15.050830   \n",
       "std        0.497669       322.881353          3.765686            11.985707   \n",
       "min        0.000000         1.000000          1.000000             1.000000   \n",
       "25%        0.000000       220.000000         10.000000             7.000000   \n",
       "50%        0.000000       376.000000         11.000000            13.000000   \n",
       "75%        1.000000       522.000000         14.000000            20.000000   \n",
       "max        1.000000      8436.000000         45.000000           321.000000   \n",
       "\n",
       "       title_sentence_count  flesch_readability  subjectivity      polarity  \\\n",
       "count          38658.000000        38658.000000  38658.000000  38658.000000   \n",
       "mean               1.067877            0.006674      0.402753      0.056997   \n",
       "std                0.270277            1.003826      0.124806      0.105170   \n",
       "min                1.000000          -83.616811      0.000000     -1.000000   \n",
       "25%                1.000000           -0.169506      0.337127      0.000000   \n",
       "50%                1.000000            0.050549      0.405745      0.054757   \n",
       "75%                1.000000            0.267479      0.475000      0.108144   \n",
       "max                4.000000            2.614284      1.000000      1.000000   \n",
       "\n",
       "       Topic 1 Probability  Topic 2 Probability  Topic 3 Probbility  \\\n",
       "count         38658.000000         38658.000000        38658.000000   \n",
       "mean              0.190953             0.324903            0.125233   \n",
       "std               0.281023             0.312565            0.210573   \n",
       "min               0.000376             0.000246            0.000120   \n",
       "25%               0.002949             0.010969            0.001305   \n",
       "50%               0.030471             0.231605            0.006765   \n",
       "75%               0.282926             0.584998            0.157612   \n",
       "max               0.997819             0.998037            0.996771   \n",
       "\n",
       "       Topic 4 Probability  Topic 5 Probability  \n",
       "count         38658.000000         38658.000000  \n",
       "mean              0.185360             0.173552  \n",
       "std               0.258829             0.234861  \n",
       "min               0.000303             0.000268  \n",
       "25%               0.003113             0.003024  \n",
       "50%               0.056382             0.056373  \n",
       "75%               0.272065             0.268291  \n",
       "max               0.998911             0.998767  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10477\n",
       "1    10477\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#first split the dataset into training and test sets\n",
    "x = data.iloc[:,1:]\n",
    "y = data.iloc[:,:1]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state = 4222)\n",
    "\n",
    "\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(x_train, y_train, test_size = 0.25, random_state = 4222)\n",
    "\n",
    "\n",
    "#balance x_train with oversampling\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "undersample = RandomUnderSampler(sampling_strategy='majority')\n",
    "# oversample = RandomOverSampler(sampling_strategy = 1)\n",
    "x_train,y_train = undersample.fit_resample(x_train, y_train)\n",
    "data = pd.concat([x_train,y_train],axis = 1)\n",
    "\n",
    "#check that train set is oversampled\n",
    "data['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we will be performing SVC, and SVC works better on scaled data, we will be scaling all our to ensure that the model runs smoothly\n",
    "# We will use the Min Max scaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Since polarity_category_Neutral and polarity_category_Positive are already from 0 to 1 scale, we will not have to further normalize it.\n",
    "cols = data.iloc[:,0:-1].columns\n",
    "\n",
    "# Normalize the data , since the data is not normally distributed we will use minmaxscaler\n",
    "x_train[cols] = scaler.fit_transform(x_train[cols]) \n",
    "\n",
    "x_test[cols] = scaler.transform(x_test[cols])\n",
    "x_validation[cols] = scaler.transform(x_validation[cols])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_word_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>text_sentence_count</th>\n",
       "      <th>title_sentence_count</th>\n",
       "      <th>flesch_readability</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>polarity</th>\n",
       "      <th>Topic 1 Probability</th>\n",
       "      <th>Topic 2 Probability</th>\n",
       "      <th>Topic 3 Probbility</th>\n",
       "      <th>Topic 4 Probability</th>\n",
       "      <th>Topic 5 Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.095400e+04</td>\n",
       "      <td>2.095400e+04</td>\n",
       "      <td>2.095400e+04</td>\n",
       "      <td>2.095400e+04</td>\n",
       "      <td>2.095400e+04</td>\n",
       "      <td>2.095400e+04</td>\n",
       "      <td>2.095400e+04</td>\n",
       "      <td>2.095400e+04</td>\n",
       "      <td>2.095400e+04</td>\n",
       "      <td>2.095400e+04</td>\n",
       "      <td>2.095400e+04</td>\n",
       "      <td>2.095400e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.485984e-16</td>\n",
       "      <td>6.437250e-14</td>\n",
       "      <td>-1.452869e-16</td>\n",
       "      <td>-3.251644e-15</td>\n",
       "      <td>2.527858e-17</td>\n",
       "      <td>1.047745e-15</td>\n",
       "      <td>3.842122e-17</td>\n",
       "      <td>2.980446e-16</td>\n",
       "      <td>-7.839990e-16</td>\n",
       "      <td>-9.346081e-17</td>\n",
       "      <td>-7.456413e-17</td>\n",
       "      <td>5.200415e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000024e+00</td>\n",
       "      <td>1.000024e+00</td>\n",
       "      <td>1.000024e+00</td>\n",
       "      <td>1.000024e+00</td>\n",
       "      <td>1.000024e+00</td>\n",
       "      <td>1.000024e+00</td>\n",
       "      <td>1.000024e+00</td>\n",
       "      <td>1.000024e+00</td>\n",
       "      <td>1.000024e+00</td>\n",
       "      <td>1.000024e+00</td>\n",
       "      <td>1.000024e+00</td>\n",
       "      <td>1.000024e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.265605e+00</td>\n",
       "      <td>-2.931249e+00</td>\n",
       "      <td>-1.181811e+00</td>\n",
       "      <td>-2.599167e-01</td>\n",
       "      <td>-8.144205e+01</td>\n",
       "      <td>-3.257379e+00</td>\n",
       "      <td>-9.876762e+00</td>\n",
       "      <td>-6.496807e-01</td>\n",
       "      <td>-1.083736e+00</td>\n",
       "      <td>-5.955218e-01</td>\n",
       "      <td>-7.069370e-01</td>\n",
       "      <td>-7.531941e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-5.730816e-01</td>\n",
       "      <td>-6.205526e-01</td>\n",
       "      <td>-6.757172e-01</td>\n",
       "      <td>-2.599167e-01</td>\n",
       "      <td>-1.882355e-01</td>\n",
       "      <td>-5.262506e-01</td>\n",
       "      <td>-5.364375e-01</td>\n",
       "      <td>-6.405202e-01</td>\n",
       "      <td>-9.950502e-01</td>\n",
       "      <td>-5.901131e-01</td>\n",
       "      <td>-6.963361e-01</td>\n",
       "      <td>-7.411363e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-1.113991e-01</td>\n",
       "      <td>-1.070645e-01</td>\n",
       "      <td>-1.696237e-01</td>\n",
       "      <td>-2.599167e-01</td>\n",
       "      <td>4.439102e-02</td>\n",
       "      <td>2.714473e-02</td>\n",
       "      <td>-2.145563e-02</td>\n",
       "      <td>-5.656766e-01</td>\n",
       "      <td>-2.508576e-01</td>\n",
       "      <td>-5.576516e-01</td>\n",
       "      <td>-4.995789e-01</td>\n",
       "      <td>-4.908026e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.318160e-01</td>\n",
       "      <td>6.631676e-01</td>\n",
       "      <td>4.208187e-01</td>\n",
       "      <td>-2.599167e-01</td>\n",
       "      <td>2.727143e-01</td>\n",
       "      <td>5.783038e-01</td>\n",
       "      <td>4.809640e-01</td>\n",
       "      <td>2.483683e-01</td>\n",
       "      <td>8.481717e-01</td>\n",
       "      <td>1.572635e-01</td>\n",
       "      <td>3.226032e-01</td>\n",
       "      <td>4.335337e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.469634e+01</td>\n",
       "      <td>8.365489e+00</td>\n",
       "      <td>2.580984e+01</td>\n",
       "      <td>1.040515e+01</td>\n",
       "      <td>2.428584e+00</td>\n",
       "      <td>4.736168e+00</td>\n",
       "      <td>8.803887e+00</td>\n",
       "      <td>2.987980e+00</td>\n",
       "      <td>2.095495e+00</td>\n",
       "      <td>4.204596e+00</td>\n",
       "      <td>3.225915e+00</td>\n",
       "      <td>3.478053e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       text_word_count  title_word_count  text_sentence_count  \\\n",
       "count     2.095400e+04      2.095400e+04         2.095400e+04   \n",
       "mean     -1.485984e-16      6.437250e-14        -1.452869e-16   \n",
       "std       1.000024e+00      1.000024e+00         1.000024e+00   \n",
       "min      -1.265605e+00     -2.931249e+00        -1.181811e+00   \n",
       "25%      -5.730816e-01     -6.205526e-01        -6.757172e-01   \n",
       "50%      -1.113991e-01     -1.070645e-01        -1.696237e-01   \n",
       "75%       3.318160e-01      6.631676e-01         4.208187e-01   \n",
       "max       2.469634e+01      8.365489e+00         2.580984e+01   \n",
       "\n",
       "       title_sentence_count  flesch_readability  subjectivity      polarity  \\\n",
       "count          2.095400e+04        2.095400e+04  2.095400e+04  2.095400e+04   \n",
       "mean          -3.251644e-15        2.527858e-17  1.047745e-15  3.842122e-17   \n",
       "std            1.000024e+00        1.000024e+00  1.000024e+00  1.000024e+00   \n",
       "min           -2.599167e-01       -8.144205e+01 -3.257379e+00 -9.876762e+00   \n",
       "25%           -2.599167e-01       -1.882355e-01 -5.262506e-01 -5.364375e-01   \n",
       "50%           -2.599167e-01        4.439102e-02  2.714473e-02 -2.145563e-02   \n",
       "75%           -2.599167e-01        2.727143e-01  5.783038e-01  4.809640e-01   \n",
       "max            1.040515e+01        2.428584e+00  4.736168e+00  8.803887e+00   \n",
       "\n",
       "       Topic 1 Probability  Topic 2 Probability  Topic 3 Probbility  \\\n",
       "count         2.095400e+04         2.095400e+04        2.095400e+04   \n",
       "mean          2.980446e-16        -7.839990e-16       -9.346081e-17   \n",
       "std           1.000024e+00         1.000024e+00        1.000024e+00   \n",
       "min          -6.496807e-01        -1.083736e+00       -5.955218e-01   \n",
       "25%          -6.405202e-01        -9.950502e-01       -5.901131e-01   \n",
       "50%          -5.656766e-01        -2.508576e-01       -5.576516e-01   \n",
       "75%           2.483683e-01         8.481717e-01        1.572635e-01   \n",
       "max           2.987980e+00         2.095495e+00        4.204596e+00   \n",
       "\n",
       "       Topic 4 Probability  Topic 5 Probability  \n",
       "count         2.095400e+04         2.095400e+04  \n",
       "mean         -7.456413e-17         5.200415e-16  \n",
       "std           1.000024e+00         1.000024e+00  \n",
       "min          -7.069370e-01        -7.531941e-01  \n",
       "25%          -6.963361e-01        -7.411363e-01  \n",
       "50%          -4.995789e-01        -4.908026e-01  \n",
       "75%           3.226032e-01         4.335337e-01  \n",
       "max           3.225915e+00         3.478053e+00  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on Validation set:\n",
      "Accuracy: 0.911148473874806\n",
      "Precision: 0.9011744485820682\n",
      "Recall: 0.9019495412844036\n",
      "F1_score: 0.9015618283421695\n",
      "-------------------------------\n",
      "Performance on  Test set:\n",
      "Accuracy: 0.9084324883600621\n",
      "Precision: 0.9022209402942025\n",
      "Recall: 0.8944809837003146\n",
      "F1_score: 0.8983342906375646\n"
     ]
    }
   ],
   "source": [
    "# Linear SVM baseline model\n",
    "\n",
    "linearSVC = SVC(kernel='linear',random_state=4222)\n",
    "linearSVC.fit(x_train, np.ravel(y_train))\n",
    "y_predval_linearSVC = linearSVC.predict(x_validation)\n",
    "\n",
    "#validation metrics\n",
    "print(\"Performance on Validation set:\")\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_validation, y_predval_linearSVC))\n",
    "print(\"Precision:\", metrics.precision_score(y_validation, y_predval_linearSVC))\n",
    "print(\"Recall:\",metrics.recall_score(y_validation, y_predval_linearSVC))\n",
    "print(\"F1_score:\", metrics.f1_score(y_validation, y_predval_linearSVC))\n",
    "print(\"-------------------------------\")\n",
    "\n",
    "\n",
    "#test metrics\n",
    "y_pred_linearSVC = linearSVC.predict(x_test)\n",
    "print(\"Performance on  Test set:\")\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_linearSVC))\n",
    "print(\"Precision:\", metrics.precision_score(y_test, y_pred_linearSVC))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred_linearSVC))\n",
    "print(\"F1_score:\", metrics.f1_score(y_test, y_pred_linearSVC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyper Parameters:  {'C': 0.1, 'gamma': 1}\n"
     ]
    }
   ],
   "source": [
    "#hyperparameter tuning with gridsearch for SVM  \n",
    "\n",
    "grid_params = {\n",
    "    'C': [0.1,1, 10, 100], \n",
    "    'gamma': [1,0.1,0.01,0.001]\n",
    "    }\n",
    "\n",
    "scorer = metrics.make_scorer(metrics.f1_score)\n",
    "\n",
    "gridCV = GridSearchCV(SVC(kernel='linear',random_state=4222), param_grid = grid_params, cv = 5, scoring = scorer, n_jobs=-1)\n",
    "\n",
    "gridCV.fit(x_train,np.ravel(y_train))\n",
    "\n",
    "print(\"Best Hyper Parameters: \", gridCV.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on Validation set:\n",
      "Accuracy: 0.9110191412312467\n",
      "Precision: 0.9016064257028112\n",
      "Recall: 0.9010894495412844\n",
      "F1_score: 0.9013478634929739\n",
      "-------------------------------\n",
      "Performance on  Test set:\n",
      "Accuracy: 0.9081738230729436\n",
      "Precision: 0.9019325064897606\n",
      "Recall: 0.8941950243065485\n",
      "F1_score: 0.8980470993681793\n"
     ]
    }
   ],
   "source": [
    "finalSVC = SVC( kernel= 'linear', C= 0.1, gamma= 1, random_state = 4222)\n",
    "finalSVC.fit(x_train, np.ravel(y_train))\n",
    "y_predval_finalSVC = finalSVC.predict(x_validation)\n",
    "\n",
    "\n",
    "#validation metrics\n",
    "print(\"Performance on Validation set:\")\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_validation, y_predval_finalSVC))\n",
    "print(\"Precision:\", metrics.precision_score(y_validation, y_predval_finalSVC))\n",
    "print(\"Recall:\",metrics.recall_score(y_validation, y_predval_finalSVC))\n",
    "print(\"F1_score:\", metrics.f1_score(y_validation, y_predval_finalSVC))\n",
    "print(\"-------------------------------\")\n",
    "\n",
    "\n",
    "#test metrics\n",
    "y_predtest_linearSVC = finalSVC.predict(x_test)\n",
    "print(\"Performance on  Test set:\")\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_predtest_linearSVC))\n",
    "print(\"Precision:\", metrics.precision_score(y_test, y_predtest_linearSVC))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_predtest_linearSVC))\n",
    "print(\"F1_score:\", metrics.f1_score(y_test, y_predtest_linearSVC))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2043299c89c8cd0b4d1a6f5cf4529bd58e6a4e0fe3181a25e0d328c821cdc5c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
