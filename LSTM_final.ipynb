{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split , GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "import itertools\n",
    "import keras\n",
    "import keras.layers as layers\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        donald trump sends out embarrassing new year’s...\n",
      "1        drunk bragging trump staffer started russian c...\n",
      "2        sheriff david clarke becomes an internet joke ...\n",
      "3        trump is so obsessed he even has obama’s name ...\n",
      "4        pope francis just called out donald trump duri...\n",
      "                               ...                        \n",
      "38653    'fully committed' nato backs new us approach a...\n",
      "38654    lexisnexis withdrew two products chinese marke...\n",
      "38655    minsk cultural hub becomes authorities in shad...\n",
      "38656    vatican upbeat possibility pope francis visiti...\n",
      "38657    indonesia buy $114 billion worth russian jets ...\n",
      "Name: overall_content, Length: 38658, dtype: object 0        1\n",
      "1        1\n",
      "2        1\n",
      "3        1\n",
      "4        1\n",
      "        ..\n",
      "38653    0\n",
      "38654    0\n",
      "38655    0\n",
      "38656    0\n",
      "38657    0\n",
      "Name: class, Length: 38658, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"master_dataset/processed_data.csv\")\n",
    "# drop unwanted features\n",
    "\n",
    "\n",
    "# Drop all the column , keep only class , overall_context\n",
    "\n",
    "x = data['overall_content']\n",
    "y = data['class'] \n",
    "    \n",
    "# As we will be vectorizing the content and doing LSTM on it\n",
    "\n",
    "print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    21196\n",
       "1    17462\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    12717\n",
       "1    10477\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#first split the dataset into training and test sets\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state = 4222)\n",
    "\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(x_train, y_train, test_size = 0.25, random_state = 4222)\n",
    "\n",
    "#check that train set is balance\n",
    "y_train.value_counts()\n",
    "\n",
    "# Since the dataset is pretty balanced, Real - 55% and Fake - 45% of the data,\n",
    "# By oversampling, we will have duplicates in the model which will overtrain out model.\n",
    "# By undersampling, we might lose out on critical information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the number of maximum text \n",
    "lst = []\n",
    "words = []\n",
    "for item in x_train:\n",
    "    lst.append(len(item.split()))\n",
    "\n",
    "big_list = [item.split() for item in x_train]\n",
    "flat_list = [item for sublist in big_list for item in sublist]\n",
    "unique = list(set(flat_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207463\n",
      "5130\n"
     ]
    }
   ],
   "source": [
    "print(len(unique)) # How many different words are there\n",
    "print(max(lst)) # What the maximum word in an article "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2.1596e+04, 1.4800e+03, 7.0000e+01, 2.4000e+01, 1.2000e+01,\n",
       "        4.0000e+00, 3.0000e+00, 3.0000e+00, 0.0000e+00, 2.0000e+00]),\n",
       " array([2.0000e+00, 5.1480e+02, 1.0276e+03, 1.5404e+03, 2.0532e+03,\n",
       "        2.5660e+03, 3.0788e+03, 3.5916e+03, 4.1044e+03, 4.6172e+03,\n",
       "        5.1300e+03]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Model constants / Parameters\n",
    "max_features = 40000\n",
    "embed_size = 100\n",
    "maxlen = [500,1000]\n",
    "dense_units = [64,128]\n",
    "lstm_units = [64,128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_params = list(itertools.product(maxlen,dense_units,lstm_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(500, 64, 64),\n",
       " (500, 64, 128),\n",
       " (500, 128, 64),\n",
       " (500, 128, 128),\n",
       " (1000, 64, 64),\n",
       " (1000, 64, 128),\n",
       " (1000, 128, 64),\n",
       " (1000, 128, 128)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenized_sets(maxlen):\n",
    "    results = []\n",
    "    tokenizer = Tokenizer(num_words=max_features)\n",
    "    tokenizer.fit_on_texts(x_train.squeeze())\n",
    "\n",
    "    tokenized_train = tokenizer.texts_to_sequences(x_train.squeeze())\n",
    "    x_train_tokenized = pad_sequences(tokenized_train , maxlen=maxlen)\n",
    "    results.append(x_train_tokenized)\n",
    "\n",
    "    tokenized_val = tokenizer.texts_to_sequences(x_validation)\n",
    "    x_validation_tokenized = pad_sequences(tokenized_val , maxlen=maxlen)\n",
    "    results.append(x_validation_tokenized)\n",
    "\n",
    "    tokenized_test = tokenizer.texts_to_sequences(x_test)\n",
    "    x_test_tokenized = pad_sequences(tokenized_test , maxlen=maxlen)\n",
    "    results.append(x_test_tokenized)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build A model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model(lstm_units, dense_units):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(layers.Embedding(max_features,embed_size))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "\n",
    "    model.add(layers.LSTM(lstm_units, return_sequences=True))\n",
    "    model.add(layers.GlobalMaxPooling1D())\n",
    "\n",
    "    model.add(layers.Dense(dense_units, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(1,activation=\"sigmoid\",name=\"predictions\"))\n",
    "\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "\n",
    "early_stopping = EarlyStopping()\n",
    "\n",
    "def make_predictions(tokenized_text, model):\n",
    "    model.fit(tokenized_text[0], y_train,\n",
    "                  validation_data = (tokenized_text[1], y_validation),\n",
    "                  epochs = epochs,\n",
    "                  callbacks = [early_stopping])\n",
    "    y_pred = (model.predict(tokenized_text[2]) >= 0.5).astype(\"int\")\n",
    "    return y_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evalute the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "725/725 [==============================] - 246s 337ms/step - loss: 0.1486 - accuracy: 0.9349 - val_loss: 0.0200 - val_accuracy: 0.9933\n",
      "Epoch 2/3\n",
      "725/725 [==============================] - 245s 338ms/step - loss: 0.0106 - accuracy: 0.9973 - val_loss: 0.0275 - val_accuracy: 0.9912\n",
      "242/242 [==============================] - 21s 87ms/step\n",
      "Epoch 1/3\n",
      "725/725 [==============================] - 277s 378ms/step - loss: 0.1164 - accuracy: 0.9480 - val_loss: 0.0206 - val_accuracy: 0.9934\n",
      "Epoch 2/3\n",
      "725/725 [==============================] - 270s 372ms/step - loss: 0.0087 - accuracy: 0.9974 - val_loss: 0.0163 - val_accuracy: 0.9939\n",
      "Epoch 3/3\n",
      "725/725 [==============================] - 272s 376ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.0363 - val_accuracy: 0.9898\n",
      "242/242 [==============================] - 24s 97ms/step\n",
      "Epoch 1/3\n",
      "725/725 [==============================] - 429s 589ms/step - loss: 0.1757 - accuracy: 0.9166 - val_loss: 0.0380 - val_accuracy: 0.9863\n",
      "Epoch 2/3\n",
      "725/725 [==============================] - 420s 580ms/step - loss: 0.0205 - accuracy: 0.9945 - val_loss: 0.0188 - val_accuracy: 0.9952\n",
      "Epoch 3/3\n",
      "725/725 [==============================] - 423s 583ms/step - loss: 0.0075 - accuracy: 0.9979 - val_loss: 0.0173 - val_accuracy: 0.9952\n",
      "242/242 [==============================] - 45s 183ms/step\n",
      "Epoch 1/3\n",
      "725/725 [==============================] - 476s 654ms/step - loss: 0.1770 - accuracy: 0.9217 - val_loss: 0.0258 - val_accuracy: 0.9926\n",
      "Epoch 2/3\n",
      "725/725 [==============================] - 446s 616ms/step - loss: 0.0136 - accuracy: 0.9961 - val_loss: 0.0236 - val_accuracy: 0.9933\n",
      "Epoch 3/3\n",
      "725/725 [==============================] - 428s 590ms/step - loss: 0.0063 - accuracy: 0.9987 - val_loss: 0.0150 - val_accuracy: 0.9956\n",
      "242/242 [==============================] - 36s 145ms/step\n",
      "Epoch 1/3\n",
      "725/725 [==============================] - 476s 653ms/step - loss: 0.1345 - accuracy: 0.9428 - val_loss: 0.0159 - val_accuracy: 0.9947\n",
      "Epoch 2/3\n",
      "725/725 [==============================] - 557s 768ms/step - loss: 0.0073 - accuracy: 0.9980 - val_loss: 0.0144 - val_accuracy: 0.9962\n",
      "Epoch 3/3\n",
      "725/725 [==============================] - 534s 737ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.0189 - val_accuracy: 0.9948\n",
      "242/242 [==============================] - 59s 221ms/step\n",
      "Epoch 1/3\n",
      "725/725 [==============================] - 535s 734ms/step - loss: 0.1362 - accuracy: 0.9401 - val_loss: 0.0171 - val_accuracy: 0.9938\n",
      "Epoch 2/3\n",
      "725/725 [==============================] - 544s 750ms/step - loss: 0.0088 - accuracy: 0.9975 - val_loss: 0.0148 - val_accuracy: 0.9959\n",
      "Epoch 3/3\n",
      "725/725 [==============================] - 536s 739ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.0144 - val_accuracy: 0.9944\n",
      "242/242 [==============================] - 53s 217ms/step\n",
      "Epoch 1/3\n",
      "725/725 [==============================] - 1040s 1s/step - loss: 0.1618 - accuracy: 0.9290 - val_loss: 0.0194 - val_accuracy: 0.9938\n",
      "Epoch 2/3\n",
      "725/725 [==============================] - 1018s 1s/step - loss: 0.0145 - accuracy: 0.9965 - val_loss: 0.0221 - val_accuracy: 0.9920\n",
      "242/242 [==============================] - 104s 430ms/step\n",
      "Epoch 1/3\n",
      "725/725 [==============================] - 1072s 1s/step - loss: 0.1646 - accuracy: 0.9300 - val_loss: 0.0166 - val_accuracy: 0.9950\n",
      "Epoch 2/3\n",
      "725/725 [==============================] - 1067s 1s/step - loss: 0.0111 - accuracy: 0.9970 - val_loss: 0.0158 - val_accuracy: 0.9953\n",
      "Epoch 3/3\n",
      "725/725 [==============================] - 1073s 1s/step - loss: 0.0063 - accuracy: 0.9987 - val_loss: 0.0204 - val_accuracy: 0.9942\n",
      "242/242 [==============================] - 81s 333ms/step\n",
      "(1000, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "for parameters in candidate_params:\n",
    "    count = 1\n",
    "    accuracy = 0\n",
    "    best_params = []\n",
    "    data = tokenized_sets(parameters[0])\n",
    "    lstm = lstm_model(parameters[1], parameters[2])\n",
    "    predictions = make_predictions(data, lstm)\n",
    "    accuracy_current = metrics.accuracy_score(y_test, predictions)\n",
    "    if accuracy_current > accuracy:\n",
    "        accuracy = accuracy_current\n",
    "        best_params = parameters \n",
    "print(best_params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis after Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "725/725 [==============================] - 1044s 1s/step - loss: 0.1325 - accuracy: 0.9430 - val_loss: 0.0127 - val_accuracy: 0.9961\n",
      "Epoch 2/3\n",
      "725/725 [==============================] - 954s 1s/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.0192 - val_accuracy: 0.9933\n",
      "242/242 [==============================] - 86s 353ms/step\n"
     ]
    }
   ],
   "source": [
    "final_sets = tokenized_sets(best_params[0])\n",
    "final_lstm_model = lstm_model(best_params[1], best_params[2])\n",
    "\n",
    "history = final_lstm_model.fit(final_sets[0], y_train,\n",
    "                              validation_data = (final_sets[1], y_validation),\n",
    "                              epochs = epochs, \n",
    "                              callbacks = [early_stopping])\n",
    "y_pred = (final_lstm_model.predict(final_sets[2]) >= 0.5).astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on Test set:\n",
      "Accuracy: 0.9940506983962752\n",
      "Precision: 0.9991321955452704\n",
      "Recall: 0.9877037460680583\n",
      "F1_score: 0.9933851020995111\n"
     ]
    }
   ],
   "source": [
    "print(\"Performance on Test set:\")\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", metrics.precision_score(y_test, y_pred))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))\n",
    "print(\"F1_score:\", metrics.f1_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
