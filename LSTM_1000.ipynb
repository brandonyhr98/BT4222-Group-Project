{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split , GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "import keras.layers as layers\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        donald trump sends out embarrassing new year’s...\n",
      "1        drunk bragging trump staffer started russian c...\n",
      "2        sheriff david clarke becomes an internet joke ...\n",
      "3        trump is so obsessed he even has obama’s name ...\n",
      "4        pope francis just called out donald trump duri...\n",
      "                               ...                        \n",
      "38653    'fully committed' nato backs new us approach a...\n",
      "38654    lexisnexis withdrew two products chinese marke...\n",
      "38655    minsk cultural hub becomes authorities in shad...\n",
      "38656    vatican upbeat possibility pope francis visiti...\n",
      "38657    indonesia buy $114 billion worth russian jets ...\n",
      "Name: overall_content, Length: 38658, dtype: object 0        1\n",
      "1        1\n",
      "2        1\n",
      "3        1\n",
      "4        1\n",
      "        ..\n",
      "38653    0\n",
      "38654    0\n",
      "38655    0\n",
      "38656    0\n",
      "38657    0\n",
      "Name: class, Length: 38658, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"master_dataset/processed_data.csv\")\n",
    "# drop unwanted features\n",
    "\n",
    "\n",
    "# Drop all the column , keep only class , overall_context\n",
    "\n",
    "x = data['overall_content']\n",
    "y = data['class'] \n",
    "    \n",
    "# As we will be vectorizing the content and doing LSTM on it\n",
    "\n",
    "print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    21196\n",
       "1    17462\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    12717\n",
       "1    10477\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#first split the dataset into training and test sets\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state = 4222)\n",
    "\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(x_train, y_train, test_size = 0.25, random_state = 4222)\n",
    "\n",
    "#check that train set is balance\n",
    "y_train.value_counts()\n",
    "\n",
    "# Since the dataset is pretty balanced, Real - 55% and Fake - 45% of the data,\n",
    "# By oversampling, we will have duplicates in the model which will overtrain out model.\n",
    "# By undersampling, we might lose out on critical information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the number of maximum text \n",
    "lst = []\n",
    "words = []\n",
    "for item in x_train:\n",
    "    lst.append(len(item.split()))\n",
    "\n",
    "big_list = [item.split() for item in x_train]\n",
    "flat_list = [item for sublist in big_list for item in sublist]\n",
    "unique = list(set(flat_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207463\n",
      "5130\n"
     ]
    }
   ],
   "source": [
    "print(len(unique)) # How many different words are there\n",
    "print(max(lst)) # What the maximum word in an article "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2.1596e+04, 1.4800e+03, 7.0000e+01, 2.4000e+01, 1.2000e+01,\n",
       "        4.0000e+00, 3.0000e+00, 3.0000e+00, 0.0000e+00, 2.0000e+00]),\n",
       " array([2.0000e+00, 5.1480e+02, 1.0276e+03, 1.5404e+03, 2.0532e+03,\n",
       "        2.5660e+03, 3.0788e+03, 3.5916e+03, 4.1044e+03, 4.6172e+03,\n",
       "        5.1300e+03]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Model constants.\n",
    "\n",
    "max_features = 20000\n",
    "maxlen = 1000 # Set a max length of the array, if not it will do an array of like [1,10000] , and if i would to run the LSTM, it will take 30 hours\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(x_train.squeeze())\n",
    "tokenized_train = tokenizer.texts_to_sequences(x_train.squeeze())\n",
    "x_train = pad_sequences(tokenized_train , maxlen=maxlen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,   531,   251,  1883],\n",
       "       [    0,     0,     0, ...,  6672,   412,   341],\n",
       "       [    0,     0,     0, ...,  7288,  7240,  3003],\n",
       "       ...,\n",
       "       [    0,     0,     0, ...,  6672,   412,   341],\n",
       "       [    0,     0,     0, ..., 12182,  7908,   300],\n",
       "       [    0,     0,     0, ...,    28,   104,  3003]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_test = tokenizer.texts_to_sequences(x_validation)\n",
    "x_validation = pad_sequences(tokenized_test , maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,  355,   25,   19],\n",
       "       [   0,    0,    0, ..., 3628,  412,  341],\n",
       "       [   0,    0,    0, ..., 2772,  412,  341],\n",
       "       ...,\n",
       "       [   0,    0,    0, ..., 3582,  412,  341],\n",
       "       [   0,    0,    0, ..., 1239,   13,  392],\n",
       "       [   0,    0,    0, ...,   15,    1,   93]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_test = tokenizer.texts_to_sequences(x_test)\n",
    "x_test = pad_sequences(tokenized_test , maxlen=maxlen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,  8425,    85,   548],\n",
       "       [    0,     0,     0, ...,  2814,  3091,  1620],\n",
       "       [    0,     0,     0, ...,   172,   104,  4504],\n",
       "       ...,\n",
       "       [    0,     0,     0, ...,    15,     1,    93],\n",
       "       [    0,     0,     0, ...,   164,  6376,   933],\n",
       "       [    0,     0,     0, ...,    92, 10793,  4960]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build A model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 20000\n",
    "batch_size = 256\n",
    "epochs = 10\n",
    "embed_size = 100\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(layers.Embedding(max_features,embed_size))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "model.add(layers.LSTM(128, return_sequences=True))\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1,activation=\"sigmoid\",name=\"predictions\"))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evalute the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, None, 100)         2000000   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, None, 100)         0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, None, 128)         117248    \n",
      "                                                                 \n",
      " global_max_pooling1d_1 (Glo  (None, 128)              0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                4128      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,121,409\n",
      "Trainable params: 2,121,409\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "725/725 [==============================] - 1050s 1s/step - loss: 0.1762 - accuracy: 0.9189 - val_loss: 0.0159 - val_accuracy: 0.9953\n",
      "Epoch 2/2\n",
      "725/725 [==============================] - 1141s 2s/step - loss: 0.0148 - accuracy: 0.9964 - val_loss: 0.0213 - val_accuracy: 0.9933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x124c0888cd0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,validation_data=(x_validation,y_validation),epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 82s 307ms/step\n"
     ]
    }
   ],
   "source": [
    "# Prediction if the news is fake \n",
    "# Class 1 (Fake) if predicted prob >= 0.5, else class 0 (Real)\n",
    "\n",
    "y_pred = (model.predict(x_test) >= 0.5).astype(\"int\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      4235\n",
      "           1       0.99      1.00      0.99      3497\n",
      "\n",
      "    accuracy                           0.99      7732\n",
      "   macro avg       0.99      0.99      0.99      7732\n",
      "weighted avg       0.99      0.99      0.99      7732\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis after Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "725/725 [==============================] - 212s 293ms/step - loss: 0.0023 - accuracy: 0.9993\n",
      "Accuracy of the model on Training Data is -  99.9267041683197 %\n",
      "242/242 [==============================] - 62s 254ms/step - loss: 0.0213 - accuracy: 0.9933\n",
      "Accuracy of the model on Validation Data is -  99.32746887207031 %\n",
      "242/242 [==============================] - 63s 261ms/step - loss: 0.0145 - accuracy: 0.9944\n",
      "Accuracy of the model on Testing Data is -  99.44387078285217 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of the model on Training Data is - \" , model.evaluate(x_train,y_train)[1]*100 ,  \"%\")\n",
    "print(\"Accuracy of the model on Validation Data is - \" , model.evaluate(x_validation,y_validation)[1]*100 , \"%\")\n",
    "print(\"Accuracy of the model on Testing Data is - \" , model.evaluate(x_test,y_test)[1]*100 , \"%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
