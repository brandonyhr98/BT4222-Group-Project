{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split , GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "import itertools\n",
    "import keras\n",
    "from keras import regularizers\n",
    "import keras.layers as layers\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        donald trump sends out embarrassing new year’s...\n",
      "1        drunk bragging trump staffer started russian c...\n",
      "2        sheriff david clarke becomes an internet joke ...\n",
      "3        trump is so obsessed he even has obama’s name ...\n",
      "4        pope francis just called out donald trump duri...\n",
      "                               ...                        \n",
      "38653    'fully committed' nato backs new us approach a...\n",
      "38654    lexisnexis withdrew two products chinese marke...\n",
      "38655    minsk cultural hub becomes authorities in shad...\n",
      "38656    vatican upbeat possibility pope francis visiti...\n",
      "38657    indonesia buy $114 billion worth russian jets ...\n",
      "Name: overall_content, Length: 38658, dtype: object 0        1\n",
      "1        1\n",
      "2        1\n",
      "3        1\n",
      "4        1\n",
      "        ..\n",
      "38653    0\n",
      "38654    0\n",
      "38655    0\n",
      "38656    0\n",
      "38657    0\n",
      "Name: class, Length: 38658, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"../master_dataset/processed_data.csv\")\n",
    "# drop unwanted features\n",
    "\n",
    "\n",
    "# Drop all the column , keep only class , overall_context\n",
    "\n",
    "x = data['overall_content']\n",
    "y = data['class'] \n",
    "    \n",
    "# As we will be vectorizing the content and doing LSTM on it\n",
    "\n",
    "print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    21196\n",
       "1    17462\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    12717\n",
       "1    10477\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#first split the dataset into training and test sets\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state = 4222)\n",
    "\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(x_train, y_train, test_size = 0.25, random_state = 4222)\n",
    "\n",
    "#check that train set is balance\n",
    "y_train.value_counts()\n",
    "\n",
    "# Since the dataset is pretty balanced, Real - 55% and Fake - 45% of the data,\n",
    "# By oversampling, we will have duplicates in the model which will overtrain out model.\n",
    "# By undersampling, we might lose out on critical information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the number of maximum text \n",
    "lst = []\n",
    "words = []\n",
    "for item in x_train:\n",
    "    lst.append(len(item.split()))\n",
    "\n",
    "big_list = [item.split() for item in x_train]\n",
    "flat_list = [item for sublist in big_list for item in sublist]\n",
    "unique = list(set(flat_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207463\n",
      "5130\n"
     ]
    }
   ],
   "source": [
    "print(len(unique)) # How many different words are there\n",
    "print(max(lst)) # What the maximum word in an article "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2.1596e+04, 1.4800e+03, 7.0000e+01, 2.4000e+01, 1.2000e+01,\n",
       "        4.0000e+00, 3.0000e+00, 3.0000e+00, 0.0000e+00, 2.0000e+00]),\n",
       " array([2.0000e+00, 5.1480e+02, 1.0276e+03, 1.5404e+03, 2.0532e+03,\n",
       "        2.5660e+03, 3.0788e+03, 3.5916e+03, 4.1044e+03, 4.6172e+03,\n",
       "        5.1300e+03]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Model constants / Parameters\n",
    "max_features = 40000 # There are a total of 200k words, based on pareto principle, 20% of the input will tell 80% of the output\n",
    "embed_size = 100\n",
    "maxlen = [500,1000] # Based on Histogram, majority of the rows have less than 1000 words , hence we decided to keep the array to 1000 max.\n",
    "dense_units = [64,128]\n",
    "lstm_units = [64,128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_params = list(itertools.product(maxlen,dense_units,lstm_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(500, 64, 64),\n",
       " (500, 64, 128),\n",
       " (500, 128, 64),\n",
       " (500, 128, 128),\n",
       " (1000, 64, 64),\n",
       " (1000, 64, 128),\n",
       " (1000, 128, 64),\n",
       " (1000, 128, 128)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenized_sets(maxlen):\n",
    "    results = []\n",
    "    tokenizer = Tokenizer(num_words=max_features)\n",
    "    tokenizer.fit_on_texts(x_train.squeeze())\n",
    "\n",
    "    tokenized_train = tokenizer.texts_to_sequences(x_train.squeeze())\n",
    "    x_train_tokenized = pad_sequences(tokenized_train , maxlen=maxlen)\n",
    "    results.append(x_train_tokenized)\n",
    "\n",
    "    tokenized_val = tokenizer.texts_to_sequences(x_validation)\n",
    "    x_validation_tokenized = pad_sequences(tokenized_val , maxlen=maxlen)\n",
    "    results.append(x_validation_tokenized)\n",
    "\n",
    "    tokenized_test = tokenizer.texts_to_sequences(x_test)\n",
    "    x_test_tokenized = pad_sequences(tokenized_test , maxlen=maxlen)\n",
    "    results.append(x_test_tokenized)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build A model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model(lstm_units, dense_units):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(layers.Embedding(max_features,embed_size))\n",
    "    \n",
    "\n",
    "    model.add(layers.LSTM(lstm_units, return_sequences=False, dropout = 0.25, \n",
    "                      recurrent_dropout = 0.25, kernel_regularizer = regularizers.l2(0.0001)))\n",
    "    \n",
    "    model.add(layers.Dropout(0.5))\n",
    "\n",
    "    model.add(layers.Dense(dense_units, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(1,activation=\"sigmoid\",name=\"predictions\"))\n",
    "\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "\n",
    "early_stopping = EarlyStopping()\n",
    "\n",
    "def make_predictions(tokenized_text, model):\n",
    "    model.fit(tokenized_text[0], y_train,\n",
    "                  validation_data = (tokenized_text[1], y_validation),\n",
    "                  epochs = epochs,\n",
    "                  callbacks = [early_stopping])\n",
    "    y_pred = (model.predict(tokenized_text[2]) >= 0.5).astype(\"int\")\n",
    "    return y_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evalute the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "725/725 [==============================] - 430s 590ms/step - loss: 0.1474 - accuracy: 0.9554 - val_loss: 0.0872 - val_accuracy: 0.9732\n",
      "Epoch 2/3\n",
      "725/725 [==============================] - 402s 554ms/step - loss: 0.0363 - accuracy: 0.9908 - val_loss: 0.0735 - val_accuracy: 0.9811\n",
      "Epoch 3/3\n",
      "725/725 [==============================] - 445s 614ms/step - loss: 0.0138 - accuracy: 0.9980 - val_loss: 0.0853 - val_accuracy: 0.9785\n",
      "242/242 [==============================] - 24s 79ms/step\n",
      "Epoch 1/3\n",
      "725/725 [==============================] - 447s 612ms/step - loss: 0.1226 - accuracy: 0.9569 - val_loss: 0.0496 - val_accuracy: 0.9882\n",
      "Epoch 2/3\n",
      "725/725 [==============================] - 428s 590ms/step - loss: 0.0214 - accuracy: 0.9956 - val_loss: 0.0628 - val_accuracy: 0.9838\n",
      "242/242 [==============================] - 20s 80ms/step\n",
      "Epoch 1/3\n",
      "725/725 [==============================] - 687s 944ms/step - loss: 0.1818 - accuracy: 0.9366 - val_loss: 0.2083 - val_accuracy: 0.9679\n",
      "Epoch 2/3\n",
      "725/725 [==============================] - 720s 993ms/step - loss: 0.0399 - accuracy: 0.9919 - val_loss: 0.0663 - val_accuracy: 0.9818\n",
      "Epoch 3/3\n",
      "725/725 [==============================] - 731s 1s/step - loss: 0.0198 - accuracy: 0.9969 - val_loss: 0.0867 - val_accuracy: 0.9768\n",
      "242/242 [==============================] - 42s 172ms/step\n",
      "Epoch 1/3\n",
      "725/725 [==============================] - 947s 1s/step - loss: 0.1271 - accuracy: 0.9570 - val_loss: 0.0676 - val_accuracy: 0.9807\n",
      "Epoch 2/3\n",
      "725/725 [==============================] - 767s 1s/step - loss: 0.0895 - accuracy: 0.9737 - val_loss: 0.1192 - val_accuracy: 0.9633\n",
      "242/242 [==============================] - 48s 198ms/step\n",
      "Epoch 1/3\n",
      "725/725 [==============================] - 1036s 1s/step - loss: 0.1661 - accuracy: 0.9449 - val_loss: 0.1229 - val_accuracy: 0.9723\n",
      "Epoch 2/3\n",
      "725/725 [==============================] - 1032s 1s/step - loss: 0.0494 - accuracy: 0.9901 - val_loss: 0.0799 - val_accuracy: 0.9793\n",
      "Epoch 3/3\n",
      "725/725 [==============================] - 1047s 1s/step - loss: 0.0257 - accuracy: 0.9956 - val_loss: 0.0863 - val_accuracy: 0.9832\n",
      "242/242 [==============================] - 38s 155ms/step\n",
      "Epoch 1/3\n",
      "725/725 [==============================] - 777s 1s/step - loss: 0.1269 - accuracy: 0.9541 - val_loss: 0.1220 - val_accuracy: 0.9553\n",
      "Epoch 2/3\n",
      "725/725 [==============================] - 828s 1s/step - loss: 0.0297 - accuracy: 0.9938 - val_loss: 0.0594 - val_accuracy: 0.9859\n",
      "Epoch 3/3\n",
      "725/725 [==============================] - 797s 1s/step - loss: 0.0097 - accuracy: 0.9982 - val_loss: 0.0764 - val_accuracy: 0.9856\n",
      "242/242 [==============================] - 30s 123ms/step\n",
      "Epoch 1/3\n",
      "725/725 [==============================] - 1322s 2s/step - loss: 0.1610 - accuracy: 0.9483 - val_loss: 0.0837 - val_accuracy: 0.9812\n",
      "Epoch 2/3\n",
      "725/725 [==============================] - 1279s 2s/step - loss: 0.1610 - accuracy: 0.9547 - val_loss: 0.1265 - val_accuracy: 0.9712\n",
      "242/242 [==============================] - 86s 352ms/step\n",
      "Epoch 1/3\n",
      "725/725 [==============================] - 1506s 2s/step - loss: 0.1293 - accuracy: 0.9574 - val_loss: 0.0482 - val_accuracy: 0.9864\n",
      "Epoch 2/3\n",
      "725/725 [==============================] - 1409s 2s/step - loss: 0.0409 - accuracy: 0.9921 - val_loss: 0.0745 - val_accuracy: 0.9781\n",
      "242/242 [==============================] - 85s 352ms/step\n",
      "(1000, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "for parameters in candidate_params:\n",
    "    count = 1\n",
    "    accuracy = 0\n",
    "    best_params = []\n",
    "    data = tokenized_sets(parameters[0])\n",
    "    lstm = lstm_model(parameters[1], parameters[2])\n",
    "    predictions = make_predictions(data, lstm)\n",
    "    accuracy_current = metrics.accuracy_score(y_test, predictions)\n",
    "    if accuracy_current > accuracy:\n",
    "        accuracy = accuracy_current\n",
    "        best_params = parameters \n",
    "print(best_params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis after Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "725/725 [==============================] - 1249s 2s/step - loss: 0.1253 - accuracy: 0.9552 - val_loss: 0.0677 - val_accuracy: 0.9825\n",
      "Epoch 2/3\n",
      "725/725 [==============================] - 1096s 2s/step - loss: 0.0268 - accuracy: 0.9948 - val_loss: 0.0493 - val_accuracy: 0.9873\n",
      "Epoch 3/3\n",
      "725/725 [==============================] - 1022s 1s/step - loss: 0.0201 - accuracy: 0.9959 - val_loss: 0.0811 - val_accuracy: 0.9780\n",
      "242/242 [==============================] - 79s 325ms/step\n"
     ]
    }
   ],
   "source": [
    "final_sets = tokenized_sets(best_params[0])\n",
    "final_lstm_model = lstm_model(best_params[1], best_params[2])\n",
    "\n",
    "history = final_lstm_model.fit(final_sets[0], y_train,\n",
    "                              validation_data = (final_sets[1], y_validation),\n",
    "                              epochs = epochs, \n",
    "                              callbacks = [early_stopping])\n",
    "y_pred = (final_lstm_model.predict(final_sets[2]) >= 0.5).astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on Test set:\n",
      "Accuracy: 0.9813760993274703\n",
      "Precision: 0.9780439121756487\n",
      "Recall: 0.9808407206176722\n",
      "F1_score: 0.9794403198172472\n"
     ]
    }
   ],
   "source": [
    "print(\"Performance on Test set:\")\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", metrics.precision_score(y_test, y_pred))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))\n",
    "print(\"F1_score:\", metrics.f1_score(y_test, y_pred))    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
