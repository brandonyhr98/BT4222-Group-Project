{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"../master_dataset/processed_data.csv\")\n",
    "\n",
    "#drop unwanted features\n",
    "data = data.drop(['title', 'text', 'subject', 'date', 'text_without_stopwords', 'title_without_stopwords','syllables', 'polarity_category', 'overall_content', 'polarity'],axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    21196\n",
       "1    17462\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['class'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset is slightly imbalanced so we will perform under sampling  to address this after the train-test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10477\n",
       "1    10477\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x = data.iloc[:,1:]\n",
    "y = data.iloc[:,:1]\n",
    "\n",
    "#first split dataset into train, validation and test sets\n",
    "#\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 4222)\n",
    "\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(x_train, y_train, test_size = 0.25, random_state = 4222)\n",
    "\n",
    "#balance x_train with oversampling\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "undersample = RandomUnderSampler(sampling_strategy = 'majority')\n",
    "x_train,y_train = undersample.fit_resample(x_train, y_train)\n",
    "data = pd.concat([x_train,y_train],axis = 1)\n",
    "\n",
    "#check that train set is oversampled\n",
    "data['class'].value_counts()\n",
    "\n",
    "#There is no need  to perform feature scaling because ensemble methods such as XGBoost and AdaBoost are not sensitive to the variance in the data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final proportion is 60% train data, 20% validation data and 20% test data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline AdaBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on Validation set:\n",
      "Accuracy: 0.9693481634764615\n",
      "Precision: 0.9672319632078183\n",
      "Recall: 0.9647362385321101\n",
      "F1_score: 0.9659824888761304\n",
      "-------------------------------\n",
      "Performance on  Test set:\n",
      "Accuracy: 0.9698654940506984\n",
      "Precision: 0.9636363636363636\n",
      "Recall: 0.9699742636545611\n",
      "F1_score: 0.966794926606812\n"
     ]
    }
   ],
   "source": [
    "ada_boost = AdaBoostClassifier( random_state = 4222)\n",
    "ada_boost.fit(x_train, np.ravel(y_train))\n",
    "y_pred_ada_boost = ada_boost.predict(x_validation)\n",
    "\n",
    "#validation metrics\n",
    "print(\"Performance on Validation set:\")\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_validation, y_pred_ada_boost))\n",
    "print(\"Precision:\", metrics.precision_score(y_validation, y_pred_ada_boost))\n",
    "print(\"Recall:\",metrics.recall_score(y_validation, y_pred_ada_boost))\n",
    "print(\"F1_score:\", metrics.f1_score(y_validation, y_pred_ada_boost))\n",
    "print(\"-------------------------------\")\n",
    "#test metrics\n",
    "y_pred_ada_boost = ada_boost.predict(x_test)\n",
    "print(\"Performance on  Test set:\")\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_ada_boost))\n",
    "print(\"Precision:\", metrics.precision_score(y_test, y_pred_ada_boost))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred_ada_boost))\n",
    "print(\"F1_score:\", metrics.f1_score(y_test, y_pred_ada_boost))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning with GridSearch (Adaboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyper Parameters:  {'algorithm': 'SAMME.R', 'learning_rate': 0.1, 'n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "grid_params = {\n",
    "    'n_estimators': [50, 100, 200,500,1000],\n",
    "    'learning_rate': [0.01, 0.1, 0.5, 1, 10],\n",
    "    'algorithm': ['SAMME', 'SAMME.R'],\n",
    "}\n",
    "scorer = metrics.make_scorer(metrics.f1_score)\n",
    "\n",
    "gridCV = GridSearchCV(AdaBoostClassifier(random_state = 4222), param_grid = grid_params, cv = 5, scoring = scorer, n_jobs=-1)\n",
    "gridCV.fit(x_train,np.ravel(y_train))\n",
    "print(\"Best Hyper Parameters: \", gridCV.best_params_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform tuning for adaboost with cross-validation to reduce the variance in the model while searching for the best parameters. Once the parameters are found, we will fit the tuned model and perform\n",
    "predictions accordingly."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuned Adaboost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on Validation set:\n",
      "Accuracy: 0.9745214692188309\n",
      "Precision: 0.9732528041415013\n",
      "Recall: 0.9701834862385321\n",
      "F1_score: 0.9717157214644652\n",
      "-------------------------------\n",
      "Performance on  Test set:\n",
      "Accuracy: 0.9725814795654423\n",
      "Precision: 0.9667519181585678\n",
      "Recall: 0.9728338575922219\n",
      "F1_score: 0.9697833523375143\n"
     ]
    }
   ],
   "source": [
    "ada_boost = AdaBoostClassifier( algorithm= 'SAMME.R', learning_rate= 0.1, n_estimators= 1000, random_state = 1)\n",
    "ada_boost.fit(x_train, np.ravel(y_train))\n",
    "y_pred_ada_boost = ada_boost.predict(x_validation)\n",
    "\n",
    "#validation metrics\n",
    "print(\"Performance on Validation set:\")\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_validation, y_pred_ada_boost))\n",
    "print(\"Precision:\", metrics.precision_score(y_validation, y_pred_ada_boost))\n",
    "print(\"Recall:\",metrics.recall_score(y_validation, y_pred_ada_boost))\n",
    "print(\"F1_score:\", metrics.f1_score(y_validation, y_pred_ada_boost))\n",
    "print(\"-------------------------------\")\n",
    "#test metrics\n",
    "y_pred_ada_boost = ada_boost.predict(x_test)\n",
    "print(\"Performance on  Test set:\")\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_ada_boost))\n",
    "print(\"Precision:\", metrics.precision_score(y_test, y_pred_ada_boost))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred_ada_boost))\n",
    "print(\"F1_score:\", metrics.f1_score(y_test, y_pred_ada_boost))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we perform the same steps for XGBoost."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on Validation set:\n",
      "Accuracy: 0.981246766683911\n",
      "Precision: 0.9832321480196589\n",
      "Recall: 0.9750573394495413\n",
      "F1_score: 0.979127681013387\n",
      "-------------------------------\n",
      "Performance on  Test set:\n",
      "Accuracy: 0.9780134505949302\n",
      "Precision: 0.978705035971223\n",
      "Recall: 0.9725478981984558\n",
      "F1_score: 0.9756167527251864\n"
     ]
    }
   ],
   "source": [
    "xg_reg = xgb.XGBClassifier(objective = 'binary:logistic') \n",
    "xg_reg.fit(x_train,np.ravel(y_train))\n",
    "\n",
    "#validation metrics\n",
    "y_pred_xg = xg_reg.predict(x_validation)\n",
    "#y_pred_xg = np.where(y_pred_xg > 0.5, 1, 0)\n",
    "\n",
    "print(\"Performance on Validation set:\")\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_validation, y_pred_xg))\n",
    "print(\"Precision:\", metrics.precision_score(y_validation, y_pred_xg))\n",
    "print(\"Recall:\",metrics.recall_score(y_validation, y_pred_xg))\n",
    "print(\"F1_score:\", metrics.f1_score(y_validation, y_pred_xg))\n",
    "print(\"-------------------------------\")\n",
    "\n",
    "#test metrics\n",
    "y_pred_xg = xg_reg.predict(x_test)\n",
    "#y_pred_xg = np.where(y_pred_xg > 0.5, 1, 0)\n",
    "\n",
    "print(\"Performance on  Test set:\")\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_xg))\n",
    "print(\"Precision:\", metrics.precision_score(y_test, y_pred_xg))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred_xg))\n",
    "print(\"F1_score:\", metrics.f1_score(y_test, y_pred_xg))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning for XGBoost using Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1296 candidates, totalling 3888 fits\n",
      "Best Hyper Parameters:  {'colsample_bytree': 0.6, 'gamma': 0.5, 'learning_rate': 0.3, 'max_depth': 3, 'n_estimators': 200, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "#hyperparameter tuning with gridsearch for XGBoost\n",
    "grid_params = {\n",
    "    'n_estimators': [50, 200, 300, 400],\n",
    "    'learning_rate': [0.01, 0.3, 0.5, 1],\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8],\n",
    "    'subsample': [0.6, 0.7, 0.8],\n",
    "    'gamma': [0.3, 0.4, 0.5],\n",
    "    'max_depth': [ 3, 6, 8],\n",
    "}\n",
    "scorer = metrics.make_scorer(metrics.f1_score)\n",
    "\n",
    "gridCV = GridSearchCV(estimator = xg_reg, param_grid = grid_params, cv = 3, scoring = scorer, n_jobs=-1, verbose = 1)\n",
    "gridCV.fit(x_train,np.ravel(y_train))\n",
    "print(\"Best Hyper Parameters: \", gridCV.best_params_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuned XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on Validation set:\n",
      "Accuracy: 0.981246766683911\n",
      "Precision: 0.9832321480196589\n",
      "Recall: 0.9750573394495413\n",
      "F1_score: 0.979127681013387\n",
      "-------------------------------\n",
      "Performance on  Test set:\n",
      "Accuracy: 0.9793067770305225\n",
      "Precision: 0.9771232484987132\n",
      "Recall: 0.9771232484987132\n",
      "F1_score: 0.9771232484987132\n"
     ]
    }
   ],
   "source": [
    "xg_reg = xgb.XGBClassifier(objective = 'binary:logistic', n_estimators = 200, learning_rate = 0.3, colsample_bytree = 0.6, subsample = 0.8, gamma = 0.5, max_depth = 3) \n",
    "xg_reg.fit(x_train,np.ravel(y_train))\n",
    "\n",
    "#validation metrics\n",
    "y_pred_xg = xg_reg.predict(x_validation)\n",
    "#y_pred_xg = np.where(y_pred_xg > 0.5, 1, 0)\n",
    "\n",
    "print(\"Performance on Validation set:\")\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_validation, y_pred_xg))\n",
    "print(\"Precision:\", metrics.precision_score(y_validation, y_pred_xg))\n",
    "print(\"Recall:\",metrics.recall_score(y_validation, y_pred_xg))\n",
    "print(\"F1_score:\", metrics.f1_score(y_validation, y_pred_xg))\n",
    "print(\"-------------------------------\")\n",
    "\n",
    "#test metrics\n",
    "y_pred_xg = xg_reg.predict(x_test)\n",
    "#y_pred_xg = np.where(y_pred_xg > 0.5, 1, 0)\n",
    "\n",
    "print(\"Performance on  Test set:\")\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred_xg))\n",
    "print(\"Precision:\", metrics.precision_score(y_test, y_pred_xg))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred_xg))\n",
    "print(\"F1_score:\", metrics.f1_score(y_test, y_pred_xg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
